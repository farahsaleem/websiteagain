


<p>title: “Project 2.”
output: html_document
—</p>
<div id="farah-saleem-fs7724" class="section level2">
<h2>Farah Saleem fs7724</h2>
<pre class="r"><code>#defining functioons
class_diag&lt;-function(probs,truth){
  
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1


  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}</code></pre>
<p>##Defining the dataset</p>
<pre class="r"><code>library(&quot;MASS&quot;)
survey1&lt;-na.omit(survey)</code></pre>
<p><em>This dataset is based on a college survey. The categorical variable is Exercise which has 3 groups: Left, Right and Neither. The binary variable is Sex, with groups: Male and Female. The numeric variables are Pulse (number of heart beats per minute), Height(cm), Age(years) and Number of people with Right Writing Hands (Wr.Hnd).</em></p>
<p>##MANOVA TEST</p>
<pre class="r"><code>library(ggplot2)
#Manova 
man1&lt;-manova(cbind(Age,Pulse)~Sex, data=survey1)
summary(man1)</code></pre>
<pre><code>##            Df    Pillai approx F num Df den Df Pr(&gt;F)
## Sex         1 0.0061588  0.51125      2    165 0.6007
## Residuals 166</code></pre>
<pre class="r"><code>#Type 1 error
1-(0.95^7)</code></pre>
<pre><code>## [1] 0.3016627</code></pre>
<pre class="r"><code>#Bonferroni correction
0.05/7</code></pre>
<pre><code>## [1] 0.007142857</code></pre>
<pre class="r"><code>##Testing multivariate normality for manova assumptions
ggplot(survey1, aes(x = Age, y = Pulse)) +
  geom_point(alpha = .5) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~Exer)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-3-1.png" width="672" />
<em>A one-way multivariate analysis of variance (MANOVA) was conducted to determine if for each Age and Pulse the means of each Sex category were different. The null hypothesis here is For Age and pulse, means of males and females are equal and the alternate hypothesis is that For at least one DV, at least one sex group mean is different. From the results (p value) here it is evident that for for Age and Pulse the means for each sex category are equal, so the null hypothesis is true. If this was significant, 2 Anovas would be run as well, and 4 post Hoc tests due to 4 groups of exercise present. There are 7 total tests. The possibility of type 1 error would be 0.301 and with bonferroni correction it will be 0.00714. The assumptions of a MANOVA are that they are random samples, independent observations and that DVs have a multivariate normality, which isnt necessarily being met as shown in the plot above.</em></p>
<p>##Randomization Test</p>
<pre class="r"><code>library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:MASS&#39;:
## 
##     select</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>#2 sample t test
t.test(data=survey1,Height~Sex)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Height by Sex
## t = -12.358, df = 147.99, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -15.94564 -11.54912
## sample estimates:
## mean in group Female   mean in group Male 
##             165.6026             179.3500</code></pre>
<pre class="r"><code>diff&lt;-vector() 
for(i in 1:10000){
  rand=survey1
  rand$Height=sample(rand$Height)
  diff[i]&lt;- mean(rand[rand$Sex==&#39;Female&#39;,]$Height)-mean(rand[rand$Sex==&#39;Male&#39;,]$Height)
}
  
    
data.frame(diff)%&gt;%
ggplot(aes(diff))+geom_histogram(aes(y=..density..), bins=30)+
  stat_function(fun=dt,args=list(df=24),geom=&quot;line&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code> quantile(diff,.975)</code></pre>
<pre><code>##    97.5% 
## 2.987786</code></pre>
<pre class="r"><code>  qt(.975, df=24)</code></pre>
<pre><code>## [1] 2.063899</code></pre>
<p><em>The randomization test performed here is a 2 sample T test, where the null hypothesis is that the means of Height do not differ across the two sexes, and the alternative hypothesis is that there is a difference between the 2 sexes. The test results show the p value to be 2.2 e-16 which means that thhere is a significant difference between the heights of male and females, with the mean of females being 165 cm and males being 178.8 cm. From the graph we can interpret that the null distribution and the t statistic within it. </em></p>
<p>##Linear Regression</p>
<pre class="r"><code>library(sandwich); library(lmtest)</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>#mean centering variables
Height_c&lt;-survey$Height-mean(survey1$Height)
Age_c&lt;-survey$Age-mean(survey1$Age)
#linear regression model
fit&lt;-lm(Height~ Exer*Age, data=survey1)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Height ~ Exer * Age, data = survey1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -20.5619  -6.9847  -0.9862   6.5598  24.6806 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  177.8528     3.3366  53.303   &lt;2e-16 ***
## ExerNone     -14.5782     8.9880  -1.622    0.107    
## ExerSome      -7.5966     6.2615  -1.213    0.227    
## Age           -0.1369     0.1522  -0.900    0.370    
## ExerNone:Age   0.4151     0.4009   1.035    0.302    
## ExerSome:Age   0.1251     0.3022   0.414    0.679    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.727 on 162 degrees of freedom
## Multiple R-squared:  0.07469,    Adjusted R-squared:  0.04614 
## F-statistic: 2.615 on 5 and 162 DF,  p-value: 0.02645</code></pre>
<pre class="r"><code>#plot

ggplot(survey1, aes(x=Age, y=Height,group=Sex))+geom_point(aes(color=Sex))+
 geom_smooth(method=&quot;lm&quot;,formula=y~1,se=F,fullrange=T,aes(color=Sex))+
theme(legend.position=c(.9,.19))+xlab(&quot;Age&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>#checking for assumptions of linearity, normality and homoskedasticity 
resids&lt;-fit$residuals
fitvals&lt;-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color=&#39;red&#39;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
<pre class="r"><code>ggplot()+geom_histogram(aes(resids), bins=20)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-3.png" width="672" /></p>
<pre class="r"><code>#robust standard errors 
summary(fit)$coef[,1:2]</code></pre>
<pre><code>##                 Estimate Std. Error
## (Intercept)  177.8527971  3.3366091
## ExerNone     -14.5781996  8.9880156
## ExerSome      -7.5965839  6.2615476
## Age           -0.1369404  0.1521976
## ExerNone:Age   0.4151425  0.4009248
## ExerSome:Age   0.1250937  0.3022070</code></pre>
<pre class="r"><code>coeftest(fit, vcov = vcovHC(fit))[,1:2]</code></pre>
<pre><code>##                 Estimate Std. Error
## (Intercept)  177.8527971  3.7471872
## ExerNone     -14.5781996 17.1117967
## ExerSome      -7.5965839  6.7202897
## Age           -0.1369404  0.1759690
## ExerNone:Age   0.4151425  0.8536767
## ExerSome:Age   0.1250937  0.3301722</code></pre>
<pre class="r"><code>#proportion of variation explained in the outcome explained by the model
summary(fit)$r.sq</code></pre>
<pre><code>## [1] 0.07469393</code></pre>
<p><em>Interpreting the coefficients, we see that when exercise and age is held constant, the height would be 177. When there is no exercise, the height is about 14cm lesser, with some its 7 cm lesser. With Age and exercise interacting, we see that no exercise and age means 0.4cm greater height, while with some exercise and age the height is greater by 0.12cm. the standard errors change with the coeftest because its a different sampling method and the outliers are removed. The assumption plots show that the assumptions have been met. The proportion of variation in the response variable explained by the overall model is 0.0601 as explained by the r squared value.</em></p>
<p>##Bootstrapping</p>
<pre class="r"><code>#bootstrapped standard errors
boot_dat&lt;-survey[sample(nrow(survey1),replace=TRUE),]
samp_distn&lt;-replicate(5000, {
 boot_dat&lt;-survey[sample(nrow(survey),replace=TRUE),]
 fit&lt;-lm(Height~Exer+Age,data=boot_dat)
 coef(fit)
})
samp_distn%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) ExerNone ExerSome        Age
## 1    2.021845  2.35952 1.410581 0.08908314</code></pre>
<p><em>Compared to the original SDs, all 3 are smaller with exercise none being 2.35, exercise some being 1.4,and age is 0.089.Compared to the robust SD’s, these bootstrapped sds are once again much smaller </em></p>
<p>##Logistic Regression</p>
<pre class="r"><code>library(ggplot2)
library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ────────────────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ tibble  2.1.3     ✓ purrr   0.3.3
## ✓ tidyr   1.0.0     ✓ stringr 1.4.0
## ✓ readr   1.3.1     ✓ forcats 0.4.0</code></pre>
<pre><code>## ── Conflicts ───────────────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
## x dplyr::select() masks MASS::select()</code></pre>
<pre class="r"><code>library(knitr)
#logistic regression
fit4&lt;-glm(Sex~Pulse+Height,data=survey1,family=binomial(link=&quot;logit&quot;))
coeftest(fit4)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept) -46.0051310   7.0692961 -6.5077 7.629e-11 ***
## Pulse        -0.0066152   0.0183591 -0.3603    0.7186    
## Height        0.2704565   0.0406024  6.6611 2.718e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit4))</code></pre>
<pre><code>##  (Intercept)        Pulse       Height 
## 1.047672e-20 9.934066e-01 1.310563e+00</code></pre>
<pre class="r"><code>#confusion matrix
prob&lt;- predict(fit4, type = &quot;response&quot;)
prob</code></pre>
<pre><code>##           1           2           5           6           7           8 
## 0.543699207 0.801238471 0.166402313 0.570708223 0.948186017 0.017412749 
##           9          10          11          14          17          18 
## 0.700244115 0.192435080 0.013532412 0.010761314 0.015793858 0.951034171 
##          20          21          22          23          24          27 
## 0.794077708 0.993571317 0.908270500 0.912585426 0.966062921 0.528156802 
##          28          30          32          33          34          36 
## 0.728085559 0.203997014 0.896697028 0.185810594 0.901497325 0.992931399 
##          38          39          42          44          47          48 
## 0.946691840 0.970690727 0.010182032 0.768742426 0.892962065 0.340158887 
##          49          50          51          52          53          54 
## 0.275807795 0.153089770 0.999557369 0.992837931 0.378756223 0.884538557 
##          55          57          59          61          62          63 
## 0.942021850 0.020298386 0.841827721 0.984228126 0.241935164 0.841983426 
##          65          71          73          74          75          76 
## 0.111685469 0.389146716 0.448457589 0.282840879 0.123256470 0.382875455 
##          77          79          82          85          86          87 
## 0.132094531 0.141535121 0.773413064 0.220772128 0.207238515 0.075662982 
##          88          89          91          93          95          97 
## 0.371995076 0.881808500 0.952223546 0.136711757 0.878317484 0.992837931 
##          98         100         102         104         105         106 
## 0.202452302 0.720156897 0.395454874 0.700244115 0.079443032 0.364301330 
##         109         110         111         112         113         114 
## 0.904966157 0.910989264 0.694660687 0.993224305 0.383436989 0.974229278 
##         115         116         117         118         119         120 
## 0.080421351 0.023292193 0.030306648 0.996511290 0.396854081 0.956783046 
##         122         123         124         125         127         128 
## 0.796232699 0.476214830 0.907772914 0.722815443 0.564213561 0.862326541 
##         129         130         131         132         134         135 
## 0.017412749 0.004106326 0.986087592 0.850586977 0.037115492 0.696942822 
##         136         138         140         141         143         144 
## 0.989183189 0.951646622 0.216067754 0.683321495 0.569086748 0.885134588 
##         145         146         147         148         149         150 
## 0.515882620 0.971617236 0.987949174 0.976932646 0.120425397 0.111685469 
##         151         152         153         154         155         156 
## 0.998036634 0.129090346 0.004513496 0.562586357 0.910451393 0.569812666 
##         158         160         161         163         164         166 
## 0.239516973 0.982269096 0.202924929 0.995468360 0.345064630 0.248940407 
##         167         168         170         172         174         175 
## 0.379754242 0.040829215 0.908270500 0.949152388 0.154813015 0.020563167 
##         176         177         178         180         181         182 
## 0.328382981 0.551160097 0.099218078 0.075662982 0.515882620 0.126940375 
##         183         184         185         186         187         188 
## 0.070531614 0.379754242 0.674670800 0.260237443 0.079928161 0.140662544 
##         189         190         191         192         193         194 
## 0.592352592 0.998624530 0.861168413 0.907217587 0.758665641 0.039053826 
##         196         197         198         199         200         201 
## 0.132094531 0.375648149 0.010248918 0.364301330 0.101608184 0.224014288 
##         202         204         205         206         207         208 
## 0.676288813 0.035536925 0.870389916 0.246474963 0.006740790 0.035993180 
##         209         211         212         214         215         218 
## 0.116965645 0.038360290 0.078003750 0.140662544 0.315428030 0.969147005 
##         220         222         223         227         228         229 
## 0.987188899 0.244369925 0.067744666 0.375648149 0.972866722 0.213835181 
##         230         231         233         234         236         237 
## 0.972337913 0.304237484 0.128413902 0.035086243 0.947501263 0.269826316</code></pre>
<pre class="r"><code>class_diag(prob, survey1$Sex)</code></pre>
<pre><code>##            acc      sens      spec       ppv       auc
## Male 0.8511905 0.8333333 0.8690476 0.8641975 0.9099348</code></pre>
<pre class="r"><code>table(predict = as.numeric(prob&gt;0.5), truth = survey1$Sex)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict Female Male Sum
##     0       73   14  87
##     1       11   70  81
##     Sum     84   84 168</code></pre>
<pre class="r"><code>#ROC plot 
library(plotROC)
ROCplot&lt;-ggplot(survey1)+geom_roc(aes(d=Sex,m=prob), n.cuts=0) 
ROCplot</code></pre>
<pre><code>## Warning in verify_d(data$d): D not labeled 0/1, assuming Female = 0 and Male =
## 1!</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>## Warning in verify_d(data$d): D not labeled 0/1, assuming Female = 0 and Male =
## 1!</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.9099348</code></pre>
<pre class="r"><code>#auc, accuracy,tpr
prob&lt;-predict(fit4,type=&quot;response&quot;)
class_diag&lt;-function(probs,truth){
  
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1


  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

class_diag(prob,survey1$Sex)</code></pre>
<pre><code>##            acc      sens      spec       ppv       auc
## Male 0.8511905 0.8333333 0.8690476 0.8641975 0.9099348</code></pre>
<pre class="r"><code>#density plot
odds&lt;-function(p)p/(1-p)
p&lt;-seq(0,1,by=.1)
logit&lt;-function(p)log(odds(p))
cbind(p, odds=odds(p),logit=logit(p))%&gt;%round(4)</code></pre>
<pre><code>##         p   odds   logit
##  [1,] 0.0 0.0000    -Inf
##  [2,] 0.1 0.1111 -2.1972
##  [3,] 0.2 0.2500 -1.3863
##  [4,] 0.3 0.4286 -0.8473
##  [5,] 0.4 0.6667 -0.4055
##  [6,] 0.5 1.0000  0.0000
##  [7,] 0.6 1.5000  0.4055
##  [8,] 0.7 2.3333  0.8473
##  [9,] 0.8 4.0000  1.3863
## [10,] 0.9 9.0000  2.1972
## [11,] 1.0    Inf     Inf</code></pre>
<pre class="r"><code>survey1$logit&lt;-predict(fit4) 
survey1$outcome&lt;-factor(survey1$Sex,levels=c(&quot;Male&quot;,&quot;Female&quot;))
ggplot(survey1,aes(logit, fill=as.factor(Sex)))+geom_density(alpha=.3)+
geom_vline(xintercept=0,lty=2)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
<pre class="r"><code>#10 fold CV
set.seed(1234) 
k = 10
data1 &lt;- survey[sample(nrow(survey)), ]
folds &lt;- cut(seq(1:nrow(survey)), breaks = k, labels = F) 
diags &lt;- NULL
for (i in 1:k) {
train &lt;- data1[folds != i, ]
test &lt;- data1[folds == i, ]
truth &lt;- test$Sex
fit5 &lt;- glm(Sex ~ Age+ Height , data = survey, family = &quot;binomial&quot;) 
probs &lt;- predict(fit5, newdata = test, type = &quot;response&quot;) 
preds &lt;- ifelse(probs &gt; 0.5, 1, 0)
diags &lt;- rbind(diags, class_diag(probs, truth)) 
}
diags %&gt;% summarize_all(mean)</code></pre>
<pre><code>##         acc      sens      spec       ppv auc
## 1 0.8176202 0.7817972 0.8395552 0.8444805  NA</code></pre>
<p><em>The null hypothesis for this regression are :The that with Controlling for Pulse, Height does not explain variation in sex. Controlling for Height, Pulse does not explain variation in sex. From the results it is evident that Height explains a variation in sex, of about 0.27 per unit as indicated by the coefficient estimate. Pulse does not explain variation in the sexes, with the coefficient estimate being -0.06. Accuracy is 0.85 which explains the proportion of classified cases. Sensitivity is 0.833 which explains the true positive rate.specifity is0.869 which is the true negative rate. ppv is 0.8664 which is the positive predicted value, auc 0.909 is which is why the roc graph is not a perfect curve. average out of sample acc is 08.19, sens is 0.784, spec is 0.85, ppv is 0.84. </em></p>
<p>#LASSO</p>
<pre class="r"><code>library(glmnet)</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<pre><code>## Loaded glmnet 3.0-1</code></pre>
<pre class="r"><code>y&lt;-as.matrix(survey1$Wr.Hnd)
x&lt;-survey1%&gt;%dplyr::select(Age,NW.Hnd,Height,Pulse)%&gt;%mutate_all(scale)%&gt;%as.matrix
cv&lt;-cv.glmnet(x,y)
lasso1&lt;-glmnet(x,y,lambda=cv$lambda.1se)
coef(lasso1)</code></pre>
<pre><code>## 5 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                      s0
## (Intercept) 18.80238095
## Age          .         
## NW.Hnd       1.67342375
## Height       0.04555056
## Pulse        .</code></pre>
<pre class="r"><code>#CV
set.seed(1234)
k=10
data2&lt;-survey1[sample(nrow(survey1)),] 
folds&lt;-cut(seq(1:nrow(survey1)),breaks=k,labels=F)
diags&lt;-NULL
for(i in 1:k){
 train&lt;-data2[folds!=i,]
 test&lt;-data2[folds==i,]
 fit5&lt;-lm(Wr.Hnd~NW.Hnd+Height,data=survey1)
 yhat&lt;-predict(fit,newdata=test)
 diags&lt;-mean((test$Wr.Hnd-yhat)^2)
}
mean(diags)</code></pre>
<pre><code>## [1] 23589.59</code></pre>
<pre class="r"><code>summary(fit5)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Wr.Hnd ~ NW.Hnd + Height, data = survey1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.72985 -0.30745  0.03575  0.32655  1.34788 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.312238   0.666572  -0.468  0.64010    
## NW.Hnd       0.893038   0.024880  35.893  &lt; 2e-16 ***
## Height       0.013837   0.004939   2.802  0.00569 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4938 on 165 degrees of freedom
## Multiple R-squared:  0.9346, Adjusted R-squared:  0.9338 
## F-statistic:  1179 on 2 and 165 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><em>Variables chosen are Age, NW Hnd, Height and Pulse to see the effect on the number of Writing Hnd, from the results we can see the NW Hnd and Height are the ones that have been retained/have an effect while Age and Pulse do not. The residual standard error of 0.4938 is smaller than the standard error obtained from the 10 fold CV which was 0.819 indicating a better fit. </em></p>
</div>
